name: 'GuardSpine CodeGuard'
description: 'AI-aware code governance with cryptographically verifiable evidence bundles'
author: 'GuardSpine'

branding:
  icon: 'shield'
  color: 'blue'

inputs:
  risk_threshold:
    description: 'Risk tier threshold for blocking (L0-L4). Changes at or above this level require approval.'
    required: false
    default: 'L3'
  rubric:
    description: 'Policy rubric to evaluate against (soc2, hipaa, pci-dss, or path to custom rubric)'
    required: false
    default: 'default'
  github_token:
    description: 'GitHub token for PR operations'
    required: true
    default: ${{ github.token }}
  post_comment:
    description: 'Post risk summary as PR comment'
    required: false
    default: 'true'
  generate_bundle:
    description: 'Generate evidence bundle artifact'
    required: false
    default: 'true'
  upload_sarif:
    description: 'Upload findings to GitHub Security tab (SARIF)'
    required: false
    default: 'false'
  fail_on_high_risk:
    description: 'Fail the check if risk exceeds threshold'
    required: false
    default: 'false'
  openai_api_key:
    description: 'OpenAI API key for AI-powered analysis (optional)'
    required: false
  anthropic_api_key:
    description: 'Anthropic API key for AI-powered analysis (optional)'
    required: false
  openrouter_api_key:
    description: 'OpenRouter API key for AI-powered analysis (optional) - supports 100+ models'
    required: false
  openrouter_model:
    description: 'Model to use with OpenRouter (e.g., anthropic/claude-sonnet-4, google/gemini-3)'
    required: false
    default: 'anthropic/claude-sonnet-4'
  ollama_host:
    description: 'Ollama server URL for local/on-prem AI (e.g., http://localhost:11434)'
    required: false
  ollama_model:
    description: 'Model to use with Ollama (e.g., llama3.3, codellama, mistral)'
    required: false
    default: 'llama3.3'
  model_1:
    description: 'First AI model for L1+ reviews. Format: provider/model or just model name'
    required: false
  model_2:
    description: 'Second AI model for L2+ reviews. Format: provider/model or just model name'
    required: false
  model_3:
    description: 'Third AI model for L3+ reviews. Format: provider/model or just model name'
    required: false
  ai_review:
    description: 'Enable AI-powered code review (requires at least one API key)'
    required: false
    default: 'true'
  rubrics_dir:
    description: 'Directory containing rubric YAML files (relative paths allowed)'
    required: false
    default: '.guardspine/rubrics'
  risk_policy:
    description: 'Path to YAML file defining custom risk patterns/thresholds'
    required: false
  bundle_dir:
    description: 'Directory to write evidence bundles (relative to workspace)'
    required: false
    default: '.guardspine/bundles'

outputs:
  risk_tier:
    description: 'Assessed risk tier (L0-L4)'
  risk_drivers:
    description: 'JSON array of top risk drivers'
  bundle_path:
    description: 'Path to generated evidence bundle'
  findings_count:
    description: 'Number of policy findings'
  requires_approval:
    description: 'Whether human approval is required (true/false)'
  models_used:
    description: 'Number of AI models that reviewed the change'
  consensus_risk:
    description: 'Multi-model consensus: approve, request_changes, or comment'
  agreement_score:
    description: 'How much models agreed (0.0-1.0)'

runs:
  using: 'docker'
  image: 'Dockerfile'
  args:
    - ${{ inputs.risk_threshold }}
    - ${{ inputs.rubric }}
    - ${{ inputs.github_token }}
    - ${{ inputs.post_comment }}
    - ${{ inputs.generate_bundle }}
    - ${{ inputs.upload_sarif }}
    - ${{ inputs.fail_on_high_risk }}
